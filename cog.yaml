# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md
build:
  gpu: true
  cuda: "12.1"

  python_version: "3.12"

  #python_requirements: requirements.txt
  python_packages:
    - jinja2
  run:
    - --mount=type=cache,target=/root/.cache/pip TORCH_CUDA_ARCH_LIST="9.0" CUDA_HOME=/usr/local/cuda pip install --ignore-installed \
      git+https://github.com/huggingface/transformers.git@main \
      git+https://github.com/vllm-project/vllm@main \
      accelerate
    - --mount=type=cache,target=/root/.cache/pip pip install cog==0.10.0a20
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.2/pget_linux_x86_64" && chmod +x /usr/local/bin/pget
    - sed -i "s/from vllm.model_executor.layers.quantization.schema import QuantParamSchema/# from vllm.model_executor.layers.quantization.schema import QuantParamSchema/" /root/.pyenv/versions/3.11.9/lib/python3.11/site-packages/vllm/model_executor/model_loader/weight_utils.py # hopefully this still works?
    #- ln -sf $(which echo) $(which pip)

predict: "predict.py:Predictor"
train: "train.py:train"

concurrency:
  max: 32
